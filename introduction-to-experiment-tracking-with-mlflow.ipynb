{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772946c2",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e81329",
   "metadata": {},
   "source": [
    "A term deposit is a cash investment held at a financial institution. Your money is invested for an agreed rate of interest over a fixed amount of time, or term. The bank has various outreach plans to sell term deposits to their customers such as email marketing, advertisements, telephonic marketing, and digital marketing. \n",
    "\n",
    "Telephonic marketing campaigns still remain one of the most effective way to reach out to people. However, they require huge investment as large call centers are hired to actually execute these campaigns. Hence, it is crucial to identify the customers most likely to convert beforehand so that they can be specifically targeted via call.\n",
    "\n",
    "The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe to a term deposit (variable y).\n",
    "\n",
    "[Source](https://www.kaggle.com/datasets/prakharrathi25/banking-dataset-marketing-targets)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f29d57",
   "metadata": {},
   "source": [
    "Check Python version. This be useful when creating a production environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793c8972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82261dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__ # note sklearn version too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47a25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", sep=\";\")\n",
    "test_df = pd.read_csv(\"test.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a2ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45211, 17)\n",
      "(4521, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd87a93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b37e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52853626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 600.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66b96b",
   "metadata": {},
   "source": [
    "### DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4e69e",
   "metadata": {},
   "source": [
    "Encode the categorical columns using DictVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367ff18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "trainX = train_df.drop(columns=[\"y\"])\n",
    "trainy = train_df[\"y\"]\n",
    "\n",
    "testX = test_df.drop(columns=[\"y\"])\n",
    "testy = test_df[\"y\"]\n",
    "\n",
    "trainy = trainy.replace({\"no\":0, \"yes\": 1})\n",
    "testy = testy.replace({\"no\":0, \"yes\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d267f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = dv.fit_transform(trainX.to_dict(orient=\"records\")).toarray()\n",
    "\n",
    "testX = dv.fit_transform(testX.to_dict(orient=\"records\")).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b431e1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'balance', 'campaign', 'contact', 'day', 'default', 'duration',\n",
       "       'education', 'housing', 'job', 'loan', 'marital', 'month', 'pdays',\n",
       "       'poutcome', 'previous', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c22bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'balance' 'campaign' 'contact=cellular' 'contact=telephone'\n",
      " 'contact=unknown' 'day' 'default=no' 'default=yes' 'duration'\n",
      " 'education=primary' 'education=secondary' 'education=tertiary'\n",
      " 'education=unknown' 'housing=no' 'housing=yes' 'job=admin.'\n",
      " 'job=blue-collar' 'job=entrepreneur' 'job=housemaid' 'job=management'\n",
      " 'job=retired' 'job=self-employed' 'job=services' 'job=student'\n",
      " 'job=technician' 'job=unemployed' 'job=unknown' 'loan=no' 'loan=yes'\n",
      " 'marital=divorced' 'marital=married' 'marital=single' 'month=apr'\n",
      " 'month=aug' 'month=dec' 'month=feb' 'month=jan' 'month=jul' 'month=jun'\n",
      " 'month=mar' 'month=may' 'month=nov' 'month=oct' 'month=sep' 'pdays'\n",
      " 'poutcome=failure' 'poutcome=other' 'poutcome=success' 'poutcome=unknown'\n",
      " 'previous']\n"
     ]
    }
   ],
   "source": [
    "print(dv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58303585",
   "metadata": {},
   "source": [
    "Unlike other encoders, DictVectorizer are more flexible and are very easy to apply to new data.\n",
    "\n",
    "__How it works__\n",
    "1. Convert the dataframe to a dictionary using `.to_dict(orient=\"records\")`\n",
    "2. Transform the dict dataframe using `dv.fit_transform()`, where _dv_ is the DictVecortizer object.\n",
    "3. Convert to array to avoid errors during model training: `to_array`.\n",
    "\n",
    "This encodes columns in the dataframe that are categorical, and retain values of columns that are non-categorical. \n",
    "\n",
    "The two cells above shows a comparison of the columns in the dataframe vs the columns in the dictvectorizer. You may agree that it looks similar to one-hot-encoding, concatenated to non-catgeorical columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e51c4e",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06e6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e666c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(trainX, trainy)\n",
    "y_pred = xgb.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1e5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      4092\n",
      "           1       0.69      0.84      0.76       429\n",
      "\n",
      "    accuracy                           0.95      4521\n",
      "   macro avg       0.84      0.90      0.87      4521\n",
      "weighted avg       0.96      0.95      0.95      4521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "print(classification_report(y_pred, testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529a5320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600000000000001\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63552265",
   "metadata": {},
   "source": [
    "While more feature engineering is encourged to increase the model's performance on class 1, we'll proceed to refactoring the codes and including experiment tracking with `MLflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6182e",
   "metadata": {},
   "source": [
    "### 1. Put all used libraries into one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "!pip install mlflow --quiet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b777b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle # to export and load the model\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd26baf",
   "metadata": {},
   "source": [
    "If this is your first time with [mlflow](https://www.mlflow.org/docs/latest/index.html), it is one of those tools used in machine learning operations that helps to keep track of data, models, experiment results, etc. This helps you to know what models performed best, their hyperparameters, the time they took to run and names of the data used for the training. You can also choose to take track of the name of the data scientist that trained the model.\n",
    "\n",
    "To start, one key thing to define is the experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d12f0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///root/mlops/week4/mlruns/1', experiment_id='1', lifecycle_stage='active', name='term-deposit-exp', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define experiment name. Give it any good name\n",
    "mlflow.set_experiment(\"term-deposit-exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc5403",
   "metadata": {},
   "source": [
    "This creates a folder in your working directory, called \"mlruns\"/1 : where 1 represents the experiement serial number. If we create a new experiment it will be number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e6f01",
   "metadata": {},
   "source": [
    "To see this, in your terminal,\n",
    "1. [Create a virtual enviroment](https://realpython.com/pipenv-guide/#pipenv-introduction) and install mlflow. `Remember to make your environment run on python 3.9`\n",
    "2. `cd` to this working directory where this particular notebook is located at. In my case, it is `week4`. Then run the following: `mlflow ui`, as shown in the image below.\n",
    "\n",
    "<img src=\"images/cli.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257757e",
   "metadata": {},
   "source": [
    "The Commands are actions we can carry out in mlflow. For a quick demo, `mlflow ui` will be used, but afterwards, we'll be working with `mlflow server`.\n",
    "\n",
    "After running mlflow ui in the current working directory, you should have something like this:\n",
    "\n",
    "<img src=\"images/gui.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ad2ba",
   "metadata": {},
   "source": [
    "We can populate the table once we tell mlflow to track any of our ML activities.\n",
    "\n",
    "So let's get started. `[Back to this Notebook]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8450af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make mlflow store your model files (artifacts) to a db, we have to define that\n",
    "# we can work with sqlite\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77b4da",
   "metadata": {},
   "source": [
    "so now, you can go back to the terminal and run `mlflow ui --backend-uri-sqlite:///mlflow.db`. This will produce the same mlflow ui except that you can now open the `Models` tab (beside Experiments)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c3743",
   "metadata": {},
   "source": [
    "## 2. Refactor the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dcfd72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path:str, test_path:str):\n",
    "    train = pd.read_csv(train_path, sep=\";\")\n",
    "    test = pd.read_csv(test_path, sep=\";\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "    \n",
    "def preprocess_data(train_data, test_data):\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    trainX = train_data.drop(columns=[\"y\"])\n",
    "    trainy = train_data[\"y\"]\n",
    "\n",
    "    testX = test_data.drop(columns=[\"y\"])\n",
    "    testy = test_df[\"y\"]\n",
    "\n",
    "    trainy = trainy.replace({\"no\":0, \"yes\": 1})\n",
    "    testy = testy.replace({\"no\":0, \"yes\": 1})\n",
    "\n",
    "    trainX = dv.fit_transform(trainX.to_dict(orient=\"records\")).toarray()\n",
    "\n",
    "    testX = dv.fit_transform(testX.to_dict(orient=\"records\")).toarray()\n",
    "    \n",
    "    return dv, trainX, trainy, testX, testy\n",
    "\n",
    "\n",
    "def train_model(trainX, trainy, testX, testy):\n",
    "\n",
    "    xgb = XGBClassifier()\n",
    "    \n",
    "    xgb.fit(trainX, trainy)\n",
    "    \n",
    "    pred = xgb.predict(testX)\n",
    "    \n",
    "    return xgb, pred\n",
    "    \n",
    "\n",
    "def evaluate(testy, pred):\n",
    "    \n",
    "    return (f1_score(testy, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "426b6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and dict vectorizer\n",
    "\n",
    "def save_model(path:str, model, encoder):\n",
    "    \n",
    "    with open(path, \"wb\") as f_out:\n",
    "        pickle.dump((model, encoder), f_out)\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd62846",
   "metadata": {},
   "source": [
    "The four functions in the two cells above are a summary of all we've done previously. The last cell is for saving the model and encoder as a pickle file. \n",
    "\n",
    "We will call all the functions in the next cell, but wrapped under [`mlflow.start_run()`](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.run)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac22518",
   "metadata": {},
   "source": [
    "## 3. Log the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6eea5437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600000000000001\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): # first start\n",
    "    \n",
    "    mlflow.set_tag(\"developer\", \"your_name\") # tell mlflow to record your name.\n",
    "    \n",
    "    mlflow.log_param(\"train-data\", \"train.csv\") # log the data path if you want\n",
    "    mlflow.log_param(\"test-data\", \"test.csv\")\n",
    "    \n",
    "    train, test = load_data(\"train.csv\", \"test.csv\") # call the first function\n",
    "    dv, trainX, trainy, testX, testy = preprocess_data(train, test) # call the second function\n",
    "    \n",
    "    xgb, pred = train_model(trainX, trainy, testX, testy) # call the third function\n",
    "    \n",
    "    # you can also log hyperparameters of the model.\n",
    "    # for example: mlflow.log_params(\"max_leaves\", \"4\")\n",
    "    \n",
    "    score = evaluate(testy, pred) # call the fourth function\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    model_path = save_model(\"term-deposit.bin\", xgb, dv) # save the model\n",
    "    \n",
    "    mlflow.log_metric(\"f1_score\", score) # tell mlflow to record the model score\n",
    "    \n",
    "    # tell mlflow where to pick the model from and where to store it at:\n",
    "    mlflow.log_artifact(local_path=model_path, artifact_path=\"xgb-model\") # tell mlflow to store the model too.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e63205",
   "metadata": {},
   "source": [
    "There is also another way of logging the model to mlflow since we are using xgboost. \n",
    "\n",
    "So instead of: `mlflow.log_artifact(local_path=\"term-deposit.bin\", artifact_path=\"xgb-model\")`\n",
    "\n",
    "Do: `mlflow.xgboost.log_model(xgb, artifact_path=\"xgb-model-version\")` as shown the cell below.\n",
    "\n",
    "**`NOTE: The cell below is an alternative to the one above. You can run both to see the difference, but ensure you use different artifact paths`**\n",
    "\n",
    "The latter is better because it stores more information about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47787362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(): # first start\n",
    "    \n",
    "    mlflow.set_tag(\"developer\", \"your_name\") # tell mlflow to record your name.\n",
    "    \n",
    "    mlflow.log_param(\"train-data\", \"train.csv\") # log the data path if you want\n",
    "    mlflow.log_param(\"test-data\", \"test.csv\")\n",
    "    \n",
    "    train, test = load_data(\"train.csv\", \"test.csv\") # call the first function\n",
    "    dv, trainX, trainy, testX, testy = preprocess_data(train, test) # call the second function\n",
    "    \n",
    "    xgb, pred = train_model(trainX, trainy, testX, testy) # call the third function\n",
    "    \n",
    "    # you can also log hyperparameters of the model.\n",
    "    # for example: mlflow.log_params(\"max_leaves\", \"4\")\n",
    "    \n",
    "    score = evaluate(testy, pred) # call the fourth function\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    model_path = save_model(\"term-deposit.bin\", xgb, dv)\n",
    "    \n",
    "    mlflow.log_metric(\"f1_score\", score)\n",
    "    \n",
    "    # changes are from here:\n",
    "    \n",
    "    # pickle dump just the dict vectoriser\n",
    "    with open(\"preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "    \n",
    "    # log the dict vectoriser\n",
    "    mlflow.log_artifact(\"preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "    \n",
    "    # log the model directly using .xgboost\n",
    "    mlflow.xgboost.log_model(xgb, artifact_path=\"xgb-model-version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a8fa1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "After successfully running the cell above, you should now have `mlflow.db` file in your working directory. To view it from the ui, go back to your terminal and run this now:\n",
    "\n",
    "`mlflow ui --backend-store-uri sqlite:///mlflow.db`\n",
    "\n",
    "Remember to run this in your working directory, as you did previously and also ensure your environment is activated.\n",
    "\n",
    "Your interface should be looking similar to mine below. Click on the time under the \"Start Time\" column, to see more details of the model and the artifacts.\n",
    "\n",
    "<img src=\"images/gui_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970ebc8",
   "metadata": {},
   "source": [
    "__Voila! We've come to the end of this note that introduces model experiementation with MLFlow.__\n",
    "\n",
    "\n",
    "THANKS FOR READING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153bf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
